Overview

Objective: Learn how to clean and prepare raw data for Machine Learning

Tools Used:

Python 3.x

Pandas

NumPy

Matplotlib

Seaborn

Scikit-learn

ğŸ“ Repository Contents
â”œâ”€â”€ README.md                           # This file
â”œâ”€â”€ Titanic-Dataset.csv                 # Original dataset
â”œâ”€â”€ titanic_preprocessing_notebook.py   # Complete Python notebook code
â”œâ”€â”€ titanic_data_preprocessing.md       # Detailed documentation
â”œâ”€â”€ titanic_processed.csv              # Final processed dataset
â””â”€â”€ task-1.pdf                         # Original task requirements


ğŸ¯ Learning Objectives Achieved
1. Data Exploration & Understanding
âœ… Imported dataset and explored basic information

âœ… Analyzed data types, shape, and structure

âœ… Identified missing values and their patterns

âœ… Examined categorical and numerical variables

2. Missing Value Treatment
âœ… Age: Imputed using median by Pclass and Sex groups

âœ… Embarked: Filled with mode (most frequent value)

âœ… Cabin: Created binary feature for presence/absence (77% missing)

3. Feature Engineering
âœ… Extracted titles from passenger names

âœ… Created family size feature (SibSp + Parch + 1)

âœ… Generated is_alone binary feature

âœ… Categorized ages into groups (Child, Teenager, Young Adult, Adult, Senior)

âœ… Created fare groups based on quartiles

4. Categorical Variable Encoding
âœ… Label Encoding: Applied to binary variable (Sex)

âœ… One-Hot Encoding: Applied to nominal variables (Embarked, Title, Age_Group, Fare_Group)

5. Outlier Detection & Treatment
âœ… Used IQR method for outlier detection

âœ… Visualized outliers using boxplots

âœ… Capped extreme fare values at 95th percentile

6. Feature Scaling
âœ… Normalization: Min-Max scaling (0-1 range)

âœ… Standardization: Z-score normalization (mean=0, std=1)

âœ… Compared and visualized scaling effects

ğŸš€ How to Run

pip install pandas numpy matplotlib seaborn scikit-learn
Execution
Clone this repository

Ensure Titanic-Dataset.csv is in the same directory

Run the Python notebook:

python titanic_preprocessing_notebook.py
Or open in Jupyter Notebook for interactive execution

ğŸ“Š Dataset Information
Original Dataset:

Rows: 891 passengers

Columns: 12 features

Target: Survived (0/1)

After Preprocessing:

Rows: 891 passengers (no data loss)

Columns: 30+ features (engineered features added)

Missing Values: 0 (all handled)

Scaled Features: Standardized numerical features

ğŸ” Key Preprocessing Steps
1. Missing Value Analysis
Column       Missing Count   Missing %
Cabin        687            77.1%
Age          177            19.9%
Embarked     2              0.2%
2. Feature Engineering Results
Titles Extracted: Mr, Mrs, Miss, Master, Rare (grouped)

Family Size Range: 1-11 members

Age Groups: 5 categories

Fare Groups: 4 quartile-based groups

3. Encoding Summary
Binary Encoding: Sex â†’ Sex_Encoded

One-Hot Features: 20+ dummy variables created

Ordinal Preserved: Pclass maintained as-is

4. Outlier Treatment
Fare Outliers: 24 extreme values capped

Method: 95th percentile capping

Reasoning: Preserve data while reducing noise

ğŸ“ˆ Key Insights Discovered
Survival Patterns:

Women had 74% survival rate vs 19% for men

First-class passengers: 63% survival rate

Children had higher survival rates

Data Quality Issues:

High cabin data missing (77%) - converted to binary feature

Age missing follows patterns by class and gender

Fare has extreme outliers requiring treatment

Feature Relationships:

Strong correlation between Pclass and Fare

Family size affects survival probability

Title extraction reveals social status information

ğŸ§  Interview Questions & Answers
This project addresses all 8 interview questions from the task:

Types of Missing Data: MCAR, MAR, MNAR explained with examples

Handling Categorical Variables: Label vs One-Hot encoding implementation

Normalization vs Standardization: Mathematical differences and use cases

Outlier Detection: IQR method, Z-score, visual techniques

Preprocessing Importance: Model performance, algorithm requirements

Encoding Comparison: Detailed analysis of encoding strategies

Data Imbalance: Techniques and evaluation metrics

Preprocessing Impact: Positive/negative effects on model accuracy

ğŸ“ Documentation
Complete Guide: titanic_data_preprocessing.md - Comprehensive documentation with theory and implementation

Code Comments: Extensive inline documentation in Python file

Visual Analysis: Charts and plots for data understanding

ğŸ¯ Business Value
This preprocessing pipeline:

Improves Data Quality: Eliminates missing values systematically

Enhances Features: Creates meaningful derived variables

Standardizes Scale: Ensures algorithm compatibility

Preserves Information: Minimal data loss during cleaning

Enables ML: Prepares data for classification algorithms

ğŸ† Learning Outcomes
By completing this task, I demonstrated proficiency in:

Data Quality Assessment: Systematic evaluation of data issues

Statistical Imputation: Strategic missing value treatment

Feature Engineering: Creative variable creation

Encoding Strategies: Appropriate categorical handling

Outlier Management: Balanced approach to extreme values

Scaling Techniques: Algorithm-appropriate normalization

Documentation: Professional code and process documentation


Completion Date: September 22, 2025

Note: This repository demonstrates best practices in data preprocessing and serves as a reference for future data science projects.
